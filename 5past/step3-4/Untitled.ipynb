{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004cca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da9a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a39f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['last_price'] > 5650000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 5650000, 'price_class'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846ef9c",
   "metadata": {},
   "source": [
    "# Деление на две выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a19487",
   "metadata": {},
   "source": [
    "Валидационная выборка — это 25% исходных данных. Как её извлечь?\n",
    "В sklearn для этого предусмотрена функция train_test_split Прежде чем разделить набор данных, нужно указать два параметра:\n",
    "Название набора, данные которого делим;\n",
    "Размер валидационной выборки (test_size). Выражается в долях — от 0 до 1. В нашем примере test_size=0.25, поскольку работаем с 25% исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b679b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345) #разбили на две выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f28ae5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid = df_valid.drop([\"last_price\",\"price_class\"], axis = 1)\n",
    "target_valid = df_valid[\"price_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23423104",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train[\"price_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7c75ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4871, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acee4a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4871,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35023af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1624, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6393008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1624,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4485c",
   "metadata": {},
   "source": [
    "# Гиперпараметры\n",
    "Помимо обычных параметров, есть ещё гиперпараметры, настройки алгоритмов обучения. В решающем дереве, например, это максимальная глубина или выбор критерия — Джини либо энтропийного. Гиперпараметры помогают улучшить модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf5dde",
   "metadata": {},
   "source": [
    "min_samples_split -  Этот гиперпараметр запрещает создавать узлы, в которые попадает слишком мало объектов обучающей выборки.\n",
    "min_samples_leaf - Листья — это нижние узлы с ответами. А гиперпараметр не разрешает создавать лист, в котором слишком мало объектов обучающей выборки. Значения гиперпараметров установлены по умолчанию, вы можете их не прописывать или, наоборот, поменять все."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd293c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1: 0.8522167487684729\n",
      "max_depth = 2: 0.8522167487684729\n",
      "max_depth = 3: 0.8466748768472906\n",
      "max_depth = 4: 0.8725369458128078\n",
      "max_depth = 5: 0.8663793103448276\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state=12345)\n",
    "    model.fit(features_train, target_train) #обучаем по обучаемым данным\n",
    "    prediction_valid = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, prediction_valid)\n",
    "    print(f\"max_depth = {i}: {accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44bd66",
   "metadata": {},
   "source": [
    "# Случайный лес \n",
    "Алгоритм обучает большое количество независимых друг от друга деревьев, а потом принимает решение на основе голосования. Случайный лес помогает улучшить результат предсказания и избежать переобучения.Никогда не задумывались, почему в жюри всегда несколько человек? Чтобы итоговая оценка выступающего была средней. Так сглаживаются личные предпочтения и ошибки. Случайный лес работает так же.Как его обучить? В библиотеке sklearn алгоритм случайного леса RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators = 3) # n_estimators - количество деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c1ed36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy наилучшей модели на валидационной выборке: RandomForestClassifier(n_estimators=8, random_state=12345) 0.8873152709359606\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_modul = None\n",
    "for i in range(1,11):   \n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators = i)\n",
    "    model.fit(features_train,target_train)\n",
    "    result = model.score(features_valid, target_valid)\n",
    "    if result > best_result:\n",
    "        best_modul = model \n",
    "        best_result = result\n",
    "    \n",
    "print(f\"Accuracy наилучшей модели на валидационной выборке: {best_modul} {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0552abc",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n",
    "Модель LogisticRegression (англ. «логистическая регрессия») лежит в модуле sklearn.linear_model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "617a23d2",
   "metadata": {},
   "source": [
    "Запишите модель в переменной, указав гиперпараметры. Для постоянства результата задайте random_state, равный 12345. Добавьте дополнительные гиперпараметры: solver='lbfgs' и max_iter=1000. Первый гиперпараметр позволяет выбрать алгоритм, который будет строить модель. Алгоритм 'lbfgs' — один из самых распространённых. Он подходит для большинства задач. Гиперпараметром max_iter задаётся максимальное количество итераций обучения. Значение этого параметра по умолчанию равно 100, но в некоторых случаях понадобится больше итераций.\n",
    "Обучите модель вызовом метода fit().\n",
    "Скопировать код PYTHON\n",
    "model = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=1000) \n",
    "model.fit(features, target) \n",
    "Обученная модель готова предсказывать. Вызовите метод predict().\n",
    "model.predict(new_item) \n",
    "Чтобы посмотреть accuracy модели, нужно вызвать функцию .score():\n",
    "model.score(features, target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "213bcfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy наилучшей модели на валидационной выборке: LogisticRegression(max_iter=1000, random_state=12345) 0.8780788177339901\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_modul = None\n",
    "for i in range(1,11):   \n",
    "    model = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=1000)\n",
    "    model.fit(features_train,target_train)\n",
    "    result = model.score(features_valid, target_valid)\n",
    "    if result > best_result:\n",
    "        best_modul = model \n",
    "        best_result = result\n",
    "    \n",
    "print(f\"Accuracy наилучшей модели на валидационной выборке: {best_modul} {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d3323c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m11\u001b[39m):   \n\u001b[0;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12345\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39mi)\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(features_train,target_train)\n\u001b[0;32m      6\u001b[0m     result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(features_valid, target_valid)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m>\u001b[39m best_result:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features_train' is not defined"
     ]
    }
   ],
   "source": [
    "best_result =  0\n",
    "best_modul = None\n",
    "for i in range(1,11):   \n",
    "    model =  DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    model.fit(features_train,target_train)\n",
    "    result = model.score(features_valid, target_valid)\n",
    "    if result > best_result:\n",
    "        best_modul = model \n",
    "        best_result = result\n",
    "    \n",
    "print(f\"Accuracy наилучшей модели на валидационной выборке: {best_modul} {best_result}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2153d714",
   "metadata": {},
   "source": [
    "Name\t         Качество\t    Скорость\n",
    "Решающее дерево\t Низкое\t        Высокая\n",
    "Случайный лес\t Высокое\t    Низкая\n",
    "Логистическая    регрессия\t    Среднее\tВысокая\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845abf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
